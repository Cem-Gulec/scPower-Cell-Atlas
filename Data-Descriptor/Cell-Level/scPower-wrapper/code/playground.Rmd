---
params: 
    collection_name: "Urethral luminal epithelia are castration-insensitive cells of the proximal prostate"
    dataset_name: "Mouse Fibromuscular Stromal Cells"
    link: "https://cellxgene.cziscience.com/collections/fbc5881f-1ee3-4ffe-8095-35e15e1a08fc"
    results_path: "C:/Users/Cem/Documents/GitHub/Helmholtz-Workspace/Data-Descriptor/Cell-Level/scPower-wrapper/results/lung/"
    dataset_path: "lung_TheIntegratedHumanLungCellAtlas.rds"
title: |
  <h3>**Collection name:**</h3>
  <span style='font-size:10pt'>`r params$collection_name`</span><br>
  <h3>**Dataset name:**</h3>
  <span style='font-size:10pt'>`r params$dataset_name`</span><br>
  <h3>[**Link**](`r params$link`)</h3>
output: html_notebook
---

---

Functions to be loaded:
```{r}
loadPackages <- function() {
  Packages <- c("DBI", "devtools", "digest", "dplyr", "DropletUtils", "HardyWeinberg", "MKmisc",
                "plotly", "pwr", "reshape2", "rols", "RPostgreSQL", "RPostgres", "scPower",
                "scuttle", "Seurat", "SeuratData", "SeuratDisk", "shiny", "stringr", "zeallot")

  suppressPackageStartupMessages(lapply(Packages, library, character.only = TRUE))

  print("Packages are loaded successfully.")
}

# Flags do not have to be in order and each flag can have whitespaces between. 
# But keywords has to be "hostIP", "assay", "tissue", "cellType"
# An example usage:
# Rscript main.R hostIP=[HOSTIP] assay=[assayName] tissue=[tissueName] cellType=[cellTypeName]
handleFlagsTags <- function(argList) {

  argSequence <- paste(unlist(argList), collapse = " ")

  hostIPSequence <- str_extract(argSequence, "hostIP(\\s)*=(\\s)*[1-9]+.[0-9]+.[0-9]+.[0-9]+")
  assaySequence <- str_extract(argSequence, "assay(\\s)*=(\\s)*[a-zA-Z0-9_]+")
  tissueSequence <- str_extract(argSequence, "tissue(\\s)*=(\\s)*[a-zA-Z0-9_]+")
  cellTypeSequence <- str_extract(argSequence, "cellType(\\s)*=(\\s)*[a-zA-Z0-9_]+")

  # arranging HOSTIP as a global variable
  if(!is.na(hostIPSequence)) HOSTIP <<- strsplit(gsub(" ", "", hostIPSequence), split = "=")[[1]][[2]] else stop("hostIP not provided.")

  # arranging assay, tissue and cell type names as a global variable
  if(!is.na(assaySequence)) ASSAYNAME <<- strsplit(gsub(" ", "", assaySequence), split = "=")[[1]][[2]] else ASSAYNAME <<- "assay_ontology_term_id"
  if(!is.na(tissueSequence)) TISSUENAME <<- strsplit(gsub(" ", "", tissueSequence), split = "=")[[1]][[2]] else TISSUENAME <<- "tissue_ontology_term_id"
  if(!is.na(cellTypeSequence)) CELLTYPENAME <<- strsplit(gsub(" ", "", cellTypeSequence), split = "=")[[1]][[2]] else CELLTYPENAME <<- "cell_type_ontology_term_id"

  print("Flags are arranged successfully.")
}

establishDBConnection <- function(hostIP) {
  connectionInstance <- dbConnect(
      Postgres(),
      dbname = "todos",
      host = toString(hostIP),
      port = 5432,
      user = "postgres",
      password = "asdasd12x")

  print("Connection to database established successfully.")
  return(connectionInstance)
}

# Used for converting ontology ids such as: 
# Cell Ontology, Experimental Factor Ontology and Uberon multi-species anatomy ontology
convertIDtoName <- function(term_id_list) {
    term_name_list <- list("efo", "uberon", "cl")
    term_name_result <- list()
    
    for (i in seq_along(term_name_list)) {
        # term is called by "rols" library which makes a query to Ontology Lookup Service (OLS)
        current_name <- term(term_name_list[[i]], term_id_list[[i]])
        
        # Add the result to the output list
        term_name_result[[i]] <- current_name@label
    }
    
    return(term_name_result)
}

# Converting from AnnData to Seurat via h5Seurat
convertH5Seurat <- function(file.name) {
  converted <- Convert(file.name, dest = "h5seurat", overwrite = TRUE)

  return(converted)
}

outputResults <- function(dataFrame, fileName) {
  resultsPath <- params$results_path
  fileName <- paste0(resultsPath, fileName, ".txt")
  write.table(dataFrame, fileName, row.names = FALSE, append = TRUE)
  write("\n", fileName, append = TRUE)
}

# clear everything from runtime memory
# except specified variable string
flushMemoryExcept <- function(except) {
  rm(list = setdiff(ls(), except))
}

listWarnings <- function() {
  warningList <- paste0(unlist(unique(names(last.warning))), collapse = "\n")
  cat(warningList)
}

# converts two different identification information into a primary key to be used in database
generateID <- function(resultTableSpecific, idToName) {
  hash <- digest(paste0(resultTableSpecific, idToName), algo = "md5")
  return(hash)
}

# Downsamples the reads for each molecule by the specified "prop",
# using the information in "sample".
# Please see: https://rdrr.io/bioc/DropletUtils/man/downsampleReads.html
# return: a list consisting of downsampled reads, proportions of 0.25, 0.5, 0.75 and complete
subsampleIntoList <- function(counts.subsampled) {
  tmp <- list()
  tmp[[length(tmp) + 1]] <- counts.subsampled

  for(s in c(0.75, 0.5, 0.25)){
    subsample <- downsampleMatrix(counts.subsampled, prop = s, bycol = TRUE)
    tmp[[length(tmp) + 1]] <- subsample
  }

  tmp <- setNames(tmp, c("complete", "subsampled75", "subsampled50", "subsampled25"))

  print("Subsampling process done successfully.")
  return(tmp)
}

# Conversion from dgCMatrix (sparse matrix) to list
sparseToList <- function(counts) {
  tmp <- matrix(data = 0L, nrow = counts@Dim[1], ncol = counts@Dim[2])

  row_pos <- counts@i + 1
  col_pos <- findInterval(seq(counts@x) - 1, counts@p[-1]) + 1
  val <- counts@x

  for (i in seq_along(val)){
      tmp[row_pos[i], col_pos[i]] <- val[i]
  }

  row.names(tmp) <- counts@Dimnames[[1]]
  colnames(tmp) <- counts@Dimnames[[2]]
  return(tmp)
}

# calculating sparsity of the count matrix
calculateZeroPerc <- function(counts) {
  zeros <- sum(counts == 0)
  non_zeros <- sum(counts != 0)
  total <- length(counts)
  return(c(zero_perc = zeros/total * 100, non_zero_perc = non_zeros/total * 100))
}

calculateGeneRanks <- function(count.matrix, idToName) {
  count.matrix <- sparseToList(count.matrix)
    
  # To speed up computation, remove all 0 genes
  count.matrix <- count.matrix[rowSums(count.matrix) > 0,]
  
  # Normalize by count per cell
  count.matrix <- t(t(count.matrix) / colSums(count.matrix))
  
  # Randomly select a fraction of the gene to be significant DE genes
  sign.genes <- rownames(count.matrix)[1:300]
  
  # Calculate gene ranks
  gene.ranks <- gene.rank.calculation(count.matrix, sign.genes)
  
  # Indicator to distinguish different list of elements belongs to different cell type results
  gene.ranks[["indicator"]] <- idToName
  
  return(gene.ranks)
}

# return: a data frame consisting of:
# matrix titles, number of cells and expressed gene counts
countObservedGenes <- function(counts.subsampled, nSamples) {

  print("Dimensions of each count matrices:")
  print(sapply(counts.subsampled, dim))

  expressed.genes.df <- NULL

  # Iterate over each count matrix
  for(name in names(counts.subsampled)){

    count.matrix <- counts.subsampled[[name]]

    # Create an annotation file (here containing only one cell type, but can be more)
    annot.df <- data.frame(individual = paste0("S", rep(1:nSamples, length.out = ncol(count.matrix))),
                            cell.type = rep("default_ct", ncol(count.matrix)))

    # Reformat count matrix into 3d pseudobulk matrix
    pseudo.bulk <- create.pseudobulk(count.matrix, annot.df)

    # Calculate expressed genes in the pseudobulk matrix
    # threshold of more than 3 counts in more 50% of the individuals
    expressed.genes <- calculate.gene.counts(pseudo.bulk, min.counts = 3, perc.indiv = 0.5)

    # Get the number of expressed genes
    num.expressed.genes <- nrow(expressed.genes)

    # Save expressed genes
    expressed.genes.df <- rbind(expressed.genes.df,
                                data.frame(matrix = name,
                                           num.cells = ncol(count.matrix),
                                           expressed.genes = num.expressed.genes))
  }

  print("Counting process done successfully.")
  return(expressed.genes.df)
}

# Estimation of negative binomial parameters for each gene
# return: a list with three elements: the normalized mean values,
# the dispersion values and the parameters of the mean-dispersion function fitted from DESeq
negBinomParamEstimation <- function(counts.subsampled) {

  # Data frame with normalized mean values
  norm.mean.values <- NULL

  # Parameter of the mean - dispersion function
  disp.param <- NULL

  for(name in names(counts.subsampled)){
    # Converting from sparse matrix to normal one
    counts.subsampled.converted <- sparseToList(counts.subsampled[[name]])
    temp <- nbinom.estimation(counts.subsampled.converted, sizeFactorMethod = "poscounts")

    # Save the normalized mean values
    norm.mean.values.temp <- temp[[1]]
    norm.mean.values.temp$matrix <- name
    norm.mean.values <- rbind(norm.mean.values, norm.mean.values.temp)

    # Save the parameter of the mean-dispersion function
    disp.param.temp <- temp[[3]]
    disp.param.temp$matrix <- name
    disp.param <- rbind(disp.param, disp.param.temp)
  }

  # First rows of the data frame with normalized mean values
  head(norm.mean.values)

  print("Estimation of negative binomial parameters done successfully.")
  return(list(norm.mean.values, disp.param))
}

# Estimation of a gamma mixed distribution over all means
# return: a data frame consisting of p1, p2, s1, s2, r1 and r2
# p1=emfit@proportions[1]     p2=emfit@proportions[2]
# s1=emfit@models[[2]]@shape  s2=emfit@models[[3]]@shape
# r1=emfit@models[[2]]@rate   r2=emfit@models[[3]]@rate
gammaMixedDistEstimation <- function(norm.mean.values, censor.points) {

  gamma.fits <- NULL

  for(name in unique(norm.mean.values$matrix)){

    # Number of cells per cell type as censoring point
    censoredPoint <- censor.points[name]

    norm.mean.values.temp <- norm.mean.values[norm.mean.values$matrix == name, ]
    gamma.fit.temp <- mixed.gamma.estimation(norm.mean.values.temp$mean,
                                             num.genes.kept = 21000,
                                             censoredPoint = censoredPoint)
    gamma.fit.temp$matrix <- name
    gamma.fits <- rbind(gamma.fits, gamma.fit.temp)
  }

  print("Estimation of a gamma mixed distribution done successfully.")
  return(gamma.fits)
}

# Comparison of gamma mixed fits with original means
compareGammaFixedFits <- function(norm.mean.values, gamma.fits) {
  g <- visualize.gamma.fits(norm.mean.values$mean[norm.mean.values$matrix == "complete"],
                            gamma.fits[gamma.fits$matrix == "complete",],
                            nGenes = 21000)
  print(g)
}

# Parameterization of the parameters of the gamma fits by the mean UMI counts per cell
# return: umi values (a data frame of mean UMIs for each subsample) and
# gamma linear fits (a data frame of )
parameterizationOfGammaFits <- function(gamma.fits, mean.umi.counts) {

  umi.values <- data.frame(mean.umi = mean.umi.counts, matrix = names(mean.umi.counts))
  
  gamma.fits <- merge(gamma.fits, umi.values, by = "matrix")

  # Convert the gamma fits from the shape-rate parametrization to the mean-sd parametrization
  gamma.fits <- convert.gamma.parameters(gamma.fits)

  visualizeLinearRelation(gamma.fits)

  # Fit relationship between gamma parameters and UMI values
  gamma.linear.fits <- umi.gamma.relation(gamma.fits)

  print(gamma.linear.fits)

  print("Parameterization of the gamma fits done successfully.")
  return(list(umi.values, gamma.linear.fits, gamma.fits))
}

# Visualize the linear relationship between gamma parameters and UMI values in plots
visualizeLinearRelation <- function(gamma.fits) {
  plot.values <- melt(gamma.fits, id.vars = c("matrix", "mean.umi"))
  plot.values <- plot.values[plot.values$variable %in% c("mean1", "mean2", "sd1", "sd2", "p1", "p2"),]
  ggplot(plot.values, aes(x = mean.umi, y = value)) +
         geom_point() +
         geom_line() +
         facet_wrap(~variable, ncol = 2, scales = "free")
}

mergeGeneCounts <- function(run, cellType, cellCount, evaluation, meanUmi, expressedGenes) {
  resultingDataFrame <- data.frame(run, names(meanUmi), cellType, cellCount,
                                   expressedGenes, meanUmi, evaluation)
  rownames(resultingDataFrame) <- NULL
  colnames(resultingDataFrame) <- c('run', 'sample', 'cell.type', 'num.cells', 'expressed.genes', 'meanUMI', 'evaluation')

  return(resultingDataFrame)
}

# [cellCount]_[#assays]_[#tissues]_[#cellTypes]: single dataset specific distinguisher
# [assayID]_[tissueID]_[cellTypeID]: result table specific distinguisher
mergeDescription <- function(cellCount, numberOfAssays, numberOfTissues, numberOfCellTypes, 
                             assayID, tissueID, cellTypeID, idToName) {
  
  datasetBodySpecific <- paste(cellCount, numberOfAssays, numberOfTissues, numberOfCellTypes, sep = "_")
  resultTableSpecific <- paste(assayID, tissueID, cellTypeID, sep = "_")

  return(list(
    datasetBodySpecific = datasetBodySpecific, 
    resultTableSpecific = resultTableSpecific,
    idToName = idToName
    ))
}

# Power calculation: simplified gamma model without optimizing the read depth
powerSRDRD <- function(nSamples, nCells, gamma.fits, disp.fun.param) {
    
    # Setting up the cell type specification
    gamma.fits$ct <- "New_ct"
    disp.fun.param$ct <- "New_ct"
    
    return(power.sameReadDepth.restrictedDoublets(nSamples = nSamples, 
                                                  nCells = nCells,
                                                  ct.freq = 1, 
                                                  type = "eqtl",
                                                  ref.study = scPower::eqtl.ref.study,
                                                  ref.study.name = "Blueprint (Monocytes)",
                                                  cellsPerLane = nCells,
                                                  gamma.parameters = gamma.fits[gamma.fits$matrix == "complete",],
                                                  ct = "New_ct", 
                                                  disp.fun.param = disp.fun.param,
                                                  mappingEfficiency = 0.8,
                                                  min.UMI.counts = 3,
                                                  perc.indiv.expr = 0.5,
                                                  sign.threshold = 0.05,
                                                  MTmethod = "Bonferroni",
                                                  multipletRate = 0))
}

# Writing a data frame into a data table inside PostgreSQL database
# Final design:
#     datasetBody table: descriptive parameters (datasetBodySpecific, resultTableSpecific)
#     downloadBody table
#     result tables: gammaLinearFits, dispersionFunctionResults, powerResults
#                    estimates (estimating gene counts), rsq (R squared error rate of the estimate)
# Data table names: descriptiveParams, gammaLinearFits, dispFunEstimation, powerResults, estimates
#                   geneRanks
writeToDatabase <- function(data.frame, table.name, append = TRUE) {
  dbWriteTable(connectionInstance, table.name, data.frame, append = append)
}
```


Preparation beforehand:
```{r}
  loadPackages()
  handleFlagsTags(list("hostIP=127.0.0.1"))
  connectionInstance <<- establishDBConnection(HOSTIP)
  
  # path of dataset location
  setwd("C:/Users/Cem/Documents/Github/dataset")
  datasetFilePath <- params$dataset_path

  # Reading the data in seurat format
  # For reading .h5seurat file: LoadH5Seurat(datasetFilePath, assays = "RNA")
  # For reading .rds      file: readRDS(datasetFilePath)
  memory.limit(999999)
  wholeDataset <- readRDS(datasetFilePath)
  print("Dataset loaded successfully.")

  # Split for each unique singular assay, tissue, cell type combination
  datasetCollectionCombinedID <- unique(paste(wholeDataset@meta.data[[ASSAYNAME]],
                                              wholeDataset@meta.data[[TISSUENAME]],
                                              wholeDataset@meta.data[[CELLTYPENAME]],
                                              sep = "_"))
  
  # Gamma linear fit and dispersion values needed later for binding with scPower
  # They are also used to estimate gene counts
  observedGeneCountsDF <- data.frame()
  gammaLinearFitsDF <- data.frame()
  dispFunParamDF <- data.frame()
  
  expressedGenesDF <- data.frame()
  gammaFits <- data.frame()
  gammaLinearFits <- data.frame()
  dispFunEstimation <- data.frame()
  power <- data.frame()
  
  numberOfAssays <- 0
  numberOfTissues <- 0
  numberOfCellTypes <- 0
  idToName <- ""
  cellCount <- 0
```


Main
Loop through cell types:
```{r}
  for(datasetID in datasetCollectionCombinedID){
      # datasetID: {[assayID], [tissueID], [cellTypeID]}
      completeDatasetID <- datasetID
      datasetID <- strsplit(datasetID, split = "_")[[1]]
      
      indexOnCollection <- which(sapply(datasetCollectionCombinedID, function(x) x == completeDatasetID))
      print(paste0("index: ", indexOnCollection, "/", length(datasetCollectionCombinedID)))
      
      # ontology ids converted to their ontology names and concatenated
      idToName <- paste(convertIDtoName(datasetID), collapse="_")
    
  
      # covering the code block with try catch in the purpose of
      # catching error for a particular cell type combination inside any dataset
      result <- tryCatch({
        
        dataset <- subset(wholeDataset, assay_ontology_term_id == datasetID[[1]] &
                                        tissue_ontology_term_id == datasetID[[2]] &
                                        cell_type_ontology_term_id == datasetID[[3]])
        
        # cell count threshold
        # if under 50, skip to the next sample
        cellCount <- dataset@assays$RNA@counts@Dim[[2]]
        if(cellCount < 50) {
          next
        }
        
        numberOfAssays <- length(levels(dataset$assay_ontology_term_id))
        numberOfTissues <- length(levels(dataset$tissue_ontology_term_id))
        numberOfCellTypes <- length(levels(dataset$cell_type_ontology_term_id))
      
        counts <- dataset@assays$RNA@counts
        countsSubsampled <- subsampleIntoList(counts)
        print(calculateZeroPerc(countsSubsampled$complete))
        
        # Calculating gene ranks
        geneRanks <- calculateGeneRanks(countsSubsampled$complete, idToName) 
    
        censorPoints <- rep(NA, length(countsSubsampled))
        names(censorPoints) <- names(countsSubsampled)
        
        meanUmi <- rep(NA, length(countsSubsampled))
        names(meanUmi) <- names(countsSubsampled)
    
        for(matrixName in names(countsSubsampled)) {
          # Number of cells per cell type as censoring point
          censorPoints[matrixName] <- 1 / ncol(countsSubsampled[[matrixName]])
    
          # Estimate the mean umi values per cell for each matrix
          meanUmi[matrixName] <- meanUMI.calculation(countsSubsampled[[matrixName]])
        }
    
        # Counting observed expressed genes
        nSamples <- tryCatch({
          if(is.null(dataset@meta.data$Donor)) {
            length(levels(dataset@meta.data$Sample))
          } else {
            length(levels(dataset@meta.data$Donor))
          }
        }, warning = function(w) {
          warning(w)
        }, error = function(e) {
          stop("Both Donor and Sample not found in the meta data.")
        })
        expressedGenesDF <- countObservedGenes(countsSubsampled, nSamples)
    
        # Estimation of negative binomial paramters for each gene
        c(normMeanValues, dispParam) %<-% negBinomParamEstimation(countsSubsampled)
    
        # Estimation of a gamma mixed distribution over all means
        gammaFits <- gammaMixedDistEstimation(normMeanValues, censorPoints)
    
        # Parameterization of the parameters of the gamma fits by the mean UMI counts per cell
        # gammaLinearFits: parameter, intercept, meanUMI
        c(umiValues, gammaLinearFits, gammaFits) %<-% parameterizationOfGammaFits(gammaFits, meanUmi)
        
        # Firstly arranging gamma linear fit values for each cell type
        tmp <- gammaLinearFits
        tmp$ct <- completeDatasetID
        gammaLinearFitsDF <- rbind(gammaLinearFitsDF, tmp)
        
        # Then also arranging disp fun parameter values for each cell type
        tmp <- dispersion.function.estimation(dispParam)
        tmp$ct <- completeDatasetID
        tmp <- tmp[, c("ct", names(tmp)[-ncol(tmp)])]
        dispFunParamDF <- rbind(dispFunParamDF, tmp)
        
        # Collecting data for validation of the model
        observedGeneCounts <- mergeGeneCounts("Run 5", completeDatasetID, cellCount, "own_count10",
                                              meanUmi, expressedGenesDF$expressed.genes)
        observedGeneCountsDF <- rbind(observedGeneCountsDF, observedGeneCounts)
        
        # dispFunEstimation: asymptDisp, extraPois
        dispFunEstimation <- dispersion.function.estimation(dispParam)
        
        # Power calculation: simplified gamma model without optimizing the read depth 
        #       name, powerDetect, exp.probs. power, sampleSize, totalCells, usableCells
        #       multipletFraction, ctCells, expressedGenes
        power <- powerSRDRD(nSamples, cellCount, gammaFits, dispFunEstimation)
        power[["idToName"]] <- idToName
        
        # Descriptive parameters passed:
        #       datasetBodySpecific: cellCount, #assays, #tissues, #cellTypes,
        #       resultTableSpecific: assayID, tissueID, cellTypeID
        descriptiveParams <- mergeDescription(cellCount,
                                              length(levels(dataset$assay_ontology_term_id)),
                                              length(levels(dataset$tissue_ontology_term_id)),
                                              length(levels(dataset$cell_type_ontology_term_id)),
                                              datasetID[[1]], datasetID[[2]], datasetID[[3]],
                                              idToName)
        # Write into respective files
        outputResults(descriptiveParams, "descriptiveParams")
        outputResults(geneRanks, "geneRanks")
        outputResults(data.frame(idToName, gammaLinearFits), "gammaLinearFits")
        outputResults(data.frame(idToName, dispFunEstimation), "dispFunEstimation")
        outputResults(power, "powerResults")
        
        # Write into database
        #writeToDatabase(descriptiveParams, "descriptiveParams")
        #writeToDatabase(geneRanks, "geneRanks")
        #writeToDatabase(gammaLinearFits, "gammaLinearFits")
        #writeToDatabase(dispFunEstimation, "dispFunEstimation")
        #writeToDatabase(power, "powerResults")
      }, 
      
       # error handling code (currently only used for outputting related informations)
      error = function(e) {
        datasetBodySpecific <- paste(numberOfAssays, numberOfTissues, numberOfCellTypes, sep = "_")
        
        errorDF <- data.frame(completeDatasetID,
                              idToName,
                              paste(e),
                              datasetBodySpecific,
                              cellCount)
        # errorDF <- merge(errorDF, expressedGenesDF, by = "cellCount")
        # gammaFits, gammaLinearFits, dispFunEstimation, power
                              
        colnames(errorDF)[3] <- "errorMessage"
        outputResults(errorDF, "error")
      })
      
       # skip current iteration of the loop if an error occurs
      if (inherits(result, "try-error")) {
        next
      }
  }
```


Validation by UMI counts per cell:
```{r}
  # Firstly appending data created to the ones already existing in the scPower library 
  gammaLinearFitsDF <- rbind(scPower::gamma.mixed.fits, gammaLinearFitsDF)
  dispFunParamDF <- rbind(scPower::disp.fun.param, dispFunParamDF)

  estimates.allSamples <- NULL
  # our own data generated from the dataset
  # run: 5 and count > 10
  estimates <- observedGeneCountsDF
  estimates$estimated.counts <- NA
  
  for(i in 1:nrow(estimates)){
    exp.probs <- scPower::estimate.exp.prob.count.param(
      nSamples = nSamples,
      nCellsCt = estimates$num.cells[i] / nSamples,
      meanCellCounts = estimates$meanUMI[i],
      gamma.mixed.fits = gammaLinearFitsDF,
      ct = estimates$cell.type[i],
      disp.fun.param = dispFunParamDF,
      min.counts = 10,
      perc.indiv = 0.5
    )
    estimates$estimated.counts[i] <- round(sum(exp.probs))
  }
  
  estimates$dataset <- "Training data set"
  estimates$threshold <- "Training data set - Count > 10"
  estimates.allSamples <- rbind(estimates.allSamples, estimates)

  # Calculating R squared error
  
  # Fitting a linear regression model between estimated and expressed gene counts
  model <- lm(estimates$estimated.counts ~ estimates$expressed.genes)

  # Calculate the R-squared value
  estimates$rsq <- summary(model)$r.squared
  
  # Firstly writing results into a file, then into the database
  outputResults(estimates, "estimates")
  #writeToDatabase(estimates, "estimates")
```


Visualizing estimate results (Not yet completed):
```{r}
  # Create a scatterplot of estimated.counts vs. expressed.genes, with meanUMI on the x-axis
  ggplot(estimates, aes(x = meanUMI, y = estimated.counts)) +
    geom_point(aes(color = cell.type)) +
    geom_line(aes(y = expressed.genes, color = cell.type), size = 1) +
    labs(x = "meanUMI", y = "estimated/expressed counts", color = "cell type") +
    theme_classic()
```


Middleware (temporary) script for pushing data into DB:
```{r}
  # set the path where the files are located
  rootPath <- "C:/Users/Cem/Documents/GitHub/Helmholtz-Workspace/Data-Descriptor/Cell-Level/scPower-wrapper/results"
  
  # get a list of all .txt files in the directory and subdirectories
  descriptiveFiles <- list.files(rootPath, recursive = TRUE, pattern = "^descriptiveParams\\.txt$", full.names = TRUE)
  
  hashResultsList <- list()
  for (file in descriptiveFiles){
    # Read the file as a data frame
    df <- read.table(file, sep = " ", header = TRUE, stringsAsFactors = FALSE)
  
    # Subset the data frame to select only the columns you want
    result_table <- df[, c("resultTableSpecific", "idToName")]
    result_table <- result_table[seq(1, nrow(result_table), by = 2), ]
    
    hashResults <- list()
    resultTableSpecific <- result_table[[1]]
    idToName <- result_table[[2]]
    
    for (i in seq_along(idToName)){
      hash <- generateID(resultTableSpecific[[i]], idToName[[i]])
      hashResults <- append(hashResults, hash)
    }
    
    hashResultsList[[length(hashResultsList) + 1]] <- hashResults
  }
```


(RECOMB)
Example results (number of cells) :
```{r}
  lapply(c("tidyverse", "pheatmap"), library, character.only = TRUE)

  metadata <- wholeDataset@meta.data

  cell_counts <- metadata %>%
    group_by(tissue, cell_type) %>%
    summarize(Count = n()) %>%
    spread(key = cell_type, value = Count, fill = 0)
  
  heatmap_data <- cell_counts %>%
    column_to_rownames("tissue") %>%
    as.matrix()
  
  #pheatmap(heatmap_data,
  #       scale = "none",
  #       cluster_rows = T,
  #       cluster_cols = T)
  
  # for one tissue datasets
  #pheatmap(heatmap_data, 
  #         scale = "none", 
  #         cluster_rows = FALSE, 
  #         cluster_cols = TRUE)
  
  # Assuming you have the matrix named 'data_matrix'
  tissue_names <- row.names(heatmap_data)
  cell_types <- colnames(heatmap_data)
  
  # Create a data frame from the matrix, and add tissue names as a column
  data_frame <- as.data.frame(heatmap_data)
  data_frame$Tissue <- tissue_names
  
  # Melt the data frame to get it in long format
  library(reshape2)
  long_data <- melt(data_frame, id.vars = "Tissue", variable.name = "CellType", value.name = "Count")
  
  # Save the long data as a CSV string
  csv_string <- paste(capture.output(write.csv(long_data, row.names = FALSE)), collapse = "\n")
  print(csv_string)
```

(RECOMB)
Results for genes
```{r}
# for #genes

  # Load libraries
  lapply(c("tidyverse"), library, character.only = TRUE)
  
  
# Function to calculate the number of expressed genes for a given tissue and cell type
num_expressed_genes <- function(cells, seurat_obj) {
  if (length(cells) == 0) {
    return(0)
  }
  
  counts_sub <- seurat_obj@assays$RNA@counts[, cells, drop = FALSE]
  num_genes <- sum(apply(counts_sub, 1, function(x) any(x > 0)))
  return(num_genes)
}

# Create a data frame with unique tissue and cell type combinations
tissue_cell_type_combinations <- unique(wholeDataset@meta.data %>% select(tissue, cell_type))

# Calculate the number of expressed genes for each unique combination of tissue and cell type
tissue_cell_type_combinations$num_genes <- mapply(function(tissue, cell_type) {
  cells <- rownames(wholeDataset@meta.data[wholeDataset@meta.data$tissue == tissue & wholeDataset@meta.data$cell_type == cell_type,])
  num_expressed_genes(cells, wholeDataset)
}, tissue_cell_type_combinations$tissue, tissue_cell_type_combinations$cell_type)
  
  
  
  
```
```{r}
# Assuming you have the matrix named 'data_matrix'
  tissue_names <- unique(tissue_cell_type_combinations$tissue)
  cell_types <- unique(tissue_cell_type_combinations$cell_type)
  
  # Create a data frame from the matrix, and add tissue names as a column
  data_frame <- tissue_cell_type_combinations
  data_frame$Tissue <- tissue_names
  
  # Melt the data frame to get it in long format
  library(reshape2)
  long_data <- melt(data_frame, id.vars = "tissue", variable.name = "cell_type", value.name = "num_genes")
  
  # Save the long data as a CSV string
  csv_string <- paste(capture.output(write.csv(long_data, row.names = FALSE)), collapse = "\n")
  print(csv_string)
```


