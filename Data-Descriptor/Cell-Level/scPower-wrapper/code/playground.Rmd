---
params: 
    collection_name: "Urethral luminal epithelia are castration-insensitive cells of the proximal prostate"
    dataset_name: "Mouse Fibromuscular Stromal Cells"
    link: "https://cellxgene.cziscience.com/collections/fbc5881f-1ee3-4ffe-8095-35e15e1a08fc"
    results_path: "C:/Users/Cem/Documents/GitHub/Helmholtz-Workspace/Data-Descriptor/Cell-Level/scPower-wrapper/results/lung/"
    dataset_path: "lung_TheIntegratedHumanLungCellAtlas.rds"
title: |
  <h3>**Collection name:**</h3>
  <span style='font-size:10pt'>`r params$collection_name`</span><br>
  <h3>**Dataset name:**</h3>
  <span style='font-size:10pt'>`r params$dataset_name`</span><br>
  <h3>[**Link**](`r params$link`)</h3>
output: html_notebook
---

<!-- when using another dataset, change: results & dataset path, num.genes.kept (mixed.gamma.estimation) -->

---

Functions to be loaded:
```{r}
loadPackages <- function() {
  Packages <- c("DBI", "devtools", "digest", "dplyr", "DropletUtils", "HardyWeinberg", "jsonlite", "MKmisc",
                "plotly", "purrr", "pwr", "reshape2", "rols", "RPostgreSQL", "RPostgres", "scPower",
                "scuttle", "Seurat", "SeuratData", "SeuratDisk", "shiny", "stringr", "zeallot")

  suppressPackageStartupMessages(lapply(Packages, library, character.only = TRUE))

  print("Packages are loaded successfully.")
}

# Flags do not have to be in order and each flag can have whitespaces between. 
# But keywords has to be "hostIP", "assay", "tissue", "cellType"
# An example usage:
# Rscript main.R hostIP=[HOSTIP] assay=[assayName] tissue=[tissueName] cellType=[cellTypeName]
handleFlagsTags <- function(argList) {

  argSequence <- paste(unlist(argList), collapse = " ")

  hostIPSequence <- str_extract(argSequence, "hostIP(\\s)*=(\\s)*[1-9]+.[0-9]+.[0-9]+.[0-9]+")
  assaySequence <- str_extract(argSequence, "assay(\\s)*=(\\s)*[a-zA-Z0-9_]+")
  tissueSequence <- str_extract(argSequence, "tissue(\\s)*=(\\s)*[a-zA-Z0-9_]+")
  cellTypeSequence <- str_extract(argSequence, "cellType(\\s)*=(\\s)*[a-zA-Z0-9_]+")

  # arranging HOSTIP as a global variable
  if(!is.na(hostIPSequence)) HOSTIP <<- strsplit(gsub(" ", "", hostIPSequence), split = "=")[[1]][[2]] else stop("hostIP not provided.")

  # arranging assay, tissue and cell type names as a global variable
  if(!is.na(assaySequence)) ASSAYNAME <<- strsplit(gsub(" ", "", assaySequence), split = "=")[[1]][[2]] else ASSAYNAME <<- "assay_ontology_term_id"
  if(!is.na(tissueSequence)) TISSUENAME <<- strsplit(gsub(" ", "", tissueSequence), split = "=")[[1]][[2]] else TISSUENAME <<- "tissue_ontology_term_id"
  if(!is.na(cellTypeSequence)) CELLTYPENAME <<- strsplit(gsub(" ", "", cellTypeSequence), split = "=")[[1]][[2]] else CELLTYPENAME <<- "cell_type_ontology_term_id"

  print("Flags are arranged successfully.")
}

establishDBConnection <- function(hostIP) {
  connectionInstance <- dbConnect(
      Postgres(),
      dbname = "todos",
      host = toString(hostIP),
      port = 5432,
      user = "postgres",
      password = "asdasd12x")

  print("Connection to database established successfully.")
  return(connectionInstance)
}

# Used for converting ontology ids such as: 
# Cell Ontology, Experimental Factor Ontology and Uberon multi-species anatomy ontology
convertIDtoName <- function(term_id_list) {
    term_name_list <- list("efo", "uberon", "cl")
    term_name_result <- list()
    
    for (i in seq_along(term_name_list)) {
        # term is called by "rols" library which makes a query to Ontology Lookup Service (OLS)
        current_name <- term(term_name_list[[i]], term_id_list[[i]])
        
        # Add the result to the output list
        term_name_result[[i]] <- current_name@label
    }
    
    return(term_name_result)
}

# Converting from AnnData to Seurat via h5Seurat
convertH5Seurat <- function(file.name) {
  converted <- Convert(file.name, dest = "h5seurat", overwrite = TRUE)

  return(converted)
}

outputResults <- function(dataFrame, fileName) {
  resultsPath <- params$results_path
  fileName <- paste0(resultsPath, fileName, ".txt")
  write.table(dataFrame, fileName, row.names = FALSE, append = TRUE)
  write("\n", fileName, append = TRUE)
}

# clear everything from runtime memory
# except specified variable string
flushMemoryExcept <- function(except) {
  rm(list = setdiff(ls(), except))
}

listWarnings <- function() {
  warningList <- paste0(unlist(unique(names(last.warning))), collapse = "\n")
  cat(warningList)
}

# converts two different identification information into a primary key to be used in database
generateID <- function(resultTableSpecific, idToName) {
  hash <- digest(paste0(resultTableSpecific, idToName), algo = "md5")
  return(hash)
}

escapeQuotes <- function(json_str) {
  return(gsub("'", "''", json_str))
}

# Downsamples the reads for each molecule by the specified "prop",
# using the information in "sample".
# Please see: https://rdrr.io/bioc/DropletUtils/man/downsampleReads.html
# return: a list consisting of downsampled reads, proportions of 0.25, 0.5, 0.75 and complete
subsampleIntoList <- function(counts.subsampled) {
  tmp <- vector("list", 4)
  
  tmp[[1]] <- counts.subsampled

  # Define the proportions
  proportions <- c(0.75, 0.5, 0.25)
  
  # Loop over the proportions and fill the list
  for(i in seq_along(proportions)){
    s <- proportions[i]
    subsample <- downsampleMatrix(counts.subsampled, prop = s, bycol = TRUE)
    tmp[[i + 1]] <- subsample
  }

  # Name the list elements
  names(tmp) <- c("complete", "subsampled75", "subsampled50", "subsampled25")

  print("Subsampling process done successfully.")
  return(tmp)
}

# Conversion from dgCMatrix (sparse matrix) to list
sparseToMatrix <- function(sparseMatrix) {
  # Get indices and values from sparse matrix
  i <- sparseMatrix@i + 1
  j <- rep(seq_len(ncol(sparseMatrix)), diff(sparseMatrix@p))
  v <- sparseMatrix@x
  
  # Create a zero matrix of the correct dimensions
  denseMatrix <- matrix(0, nrow = sparseMatrix@Dim[1], ncol = sparseMatrix@Dim[2])
  
  # Populate the non-zero entries
  denseMatrix[cbind(i, j)] <- v
  
  # Assign row and column names
  row.names(denseMatrix) <- sparseMatrix@Dimnames[[1]]
  colnames(denseMatrix) <- sparseMatrix@Dimnames[[2]]
  
  return(denseMatrix)
}

# calculating sparsity of the count matrix
calculateZeroPerc <- function(counts) {
  zeros <- sum(counts == 0)
  non_zeros <- sum(counts != 0)
  total <- length(counts)
  return(c(zero_perc = zeros/total * 100, non_zero_perc = non_zeros/total * 100))
}

calculateGeneRanks <- function(count.matrix, idToName) {
  count.matrix <- sparseToMatrix(count.matrix)
    
  # To speed up computation, remove all 0 genes
  count.matrix <- count.matrix[rowSums(count.matrix) > 0,]
  
  # Normalize by count per cell
  count.matrix <- t(t(count.matrix) / colSums(count.matrix))
  
  # Randomly select a fraction of the gene to be significant DE genes
  sign.genes <- rownames(count.matrix)[1:300]
  
  # Calculate gene ranks
  gene.ranks <- gene.rank.calculation(count.matrix, sign.genes)
  
  # Indicator to distinguish different list of elements belongs to different cell type results
  gene.ranks[["indicator"]] <- idToName
  
  return(gene.ranks)
}

# return: a data frame consisting of:
# matrix titles, number of cells and expressed gene counts
countObservedGenes <- function(counts.subsampled, nSamples) {

  print("Dimensions of each count matrices:")
  print(sapply(counts.subsampled, dim))

  expressed.genes.df <- NULL

  # Iterate over each count matrix
  for(name in names(counts.subsampled)){

    count.matrix <- counts.subsampled[[name]]

    # Create an annotation file (here containing only one cell type, but can be more)
    annot.df <- data.frame(individual = paste0("S", rep(1:nSamples, length.out = ncol(count.matrix))),
                            cell.type = rep("default_ct", ncol(count.matrix)))

    # Reformat count matrix into 3d pseudobulk matrix
    pseudo.bulk <- create.pseudobulk(count.matrix, annot.df)

    # Calculate expressed genes in the pseudobulk matrix
    # threshold of more than 3 counts in more 50% of the individuals
    expressed.genes <- calculate.gene.counts(pseudo.bulk, min.counts = 3, perc.indiv = 0.5)

    # Get the number of expressed genes
    num.expressed.genes <- nrow(expressed.genes)

    # Save expressed genes
    expressed.genes.df <- rbind(expressed.genes.df,
                                data.frame(matrix = name,
                                           num.cells = ncol(count.matrix),
                                           expressed.genes = num.expressed.genes))
  }

  print("Counting process done successfully.")
  return(expressed.genes.df)
}

# Estimation of negative binomial parameters for each gene
# return: a list with three elements: the normalized mean values,
# the dispersion values and the parameters of the mean-dispersion function fitted from DESeq
negBinomParamEstimation <- function(counts.subsampled) {

  # Data frame with normalized mean values
  norm.mean.values <- NULL

  # Parameter of the mean - dispersion function
  disp.param <- NULL

  for(name in names(counts.subsampled)){
    # Converting from sparse matrix to normal one
    counts.subsampled.converted <- sparseToMatrix(counts.subsampled[[name]])
    temp <- nbinom.estimation(counts.subsampled.converted, sizeFactorMethod = "poscounts")

    # Save the normalized mean values
    norm.mean.values.temp <- temp[[1]]
    norm.mean.values.temp$matrix <- name
    norm.mean.values <- rbind(norm.mean.values, norm.mean.values.temp)

    # Save the parameter of the mean-dispersion function
    disp.param.temp <- temp[[3]]
    disp.param.temp$matrix <- name
    disp.param <- rbind(disp.param, disp.param.temp)
  }

  # First rows of the data frame with normalized mean values
  head(norm.mean.values)

  print("Estimation of negative binomial parameters done successfully.")
  return(list(norm.mean.values, disp.param))
}

# Estimation of a gamma mixed distribution over all means
# return: a data frame consisting of p1, p2, s1, s2, r1 and r2
# p1=emfit@proportions[1]     p2=emfit@proportions[2]
# s1=emfit@models[[2]]@shape  s2=emfit@models[[3]]@shape
# r1=emfit@models[[2]]@rate   r2=emfit@models[[3]]@rate
gammaMixedDistEstimation <- function(norm.mean.values, censor.points) {

  gamma.fits <- NULL

  for(name in unique(norm.mean.values$matrix)){

    # Number of cells per cell type as censoring point
    censoredPoint <- censor.points[name]

    norm.mean.values.temp <- norm.mean.values[norm.mean.values$matrix == name, ]
    gamma.fit.temp <- mixed.gamma.estimation(norm.mean.values.temp$mean,
                                             num.genes.kept = 21000,
                                             censoredPoint = censoredPoint)
    gamma.fit.temp$matrix <- name
    gamma.fits <- rbind(gamma.fits, gamma.fit.temp)
  }

  print("Estimation of a gamma mixed distribution done successfully.")
  return(gamma.fits)
}

# Comparison of gamma mixed fits with original means
compareGammaFixedFits <- function(norm.mean.values, gamma.fits) {
  g <- visualize.gamma.fits(norm.mean.values$mean[norm.mean.values$matrix == "complete"],
                            gamma.fits[gamma.fits$matrix == "complete",],
                            nGenes = 21000)
  print(g)
}

# Parameterization of the parameters of the gamma fits by the mean UMI counts per cell
# return: umi values (a data frame of mean UMIs for each subsample) and
# gamma linear fits (a data frame of )
parameterizationOfGammaFits <- function(gamma.fits, mean.umi.counts) {

  umi.values <- data.frame(mean.umi = mean.umi.counts, matrix = names(mean.umi.counts))
  
  gamma.fits <- merge(gamma.fits, umi.values, by = "matrix")

  # Convert the gamma fits from the shape-rate parametrization to the mean-sd parametrization
  gamma.fits <- convert.gamma.parameters(gamma.fits)

  visualizeLinearRelation(gamma.fits)

  # Fit relationship between gamma parameters and UMI values
  gamma.linear.fits <- umi.gamma.relation(gamma.fits)

  print(gamma.linear.fits)

  print("Parameterization of the gamma fits done successfully.")
  return(list(umi.values, gamma.linear.fits, gamma.fits))
}

# Visualize the linear relationship between gamma parameters and UMI values in plots
visualizeLinearRelation <- function(gamma.fits) {
  plot.values <- melt(gamma.fits, id.vars = c("matrix", "mean.umi"))
  plot.values <- plot.values[plot.values$variable %in% c("mean1", "mean2", "sd1", "sd2", "p1", "p2"),]
  ggplot(plot.values, aes(x = mean.umi, y = value)) +
         geom_point() +
         geom_line() +
         facet_wrap(~variable, ncol = 2, scales = "free")
}

mergeGeneCounts <- function(run, cellType, cellCount, evaluation, meanUmi, expressedGenes) {
  resultingDataFrame <- data.frame(run, names(meanUmi), cellType, cellCount,
                                   expressedGenes, meanUmi, evaluation)
  rownames(resultingDataFrame) <- NULL
  colnames(resultingDataFrame) <- c('run', 'sample', 'cell.type', 'num.cells', 'expressed.genes', 'meanUMI', 'evaluation')

  return(resultingDataFrame)
}

# [cellCount]_[#assays]_[#tissues]_[#cellTypes]: single dataset specific distinguisher
# [assayID]_[tissueID]_[cellTypeID]: result table specific distinguisher
mergeDescription <- function(cellCount, numberOfAssays, numberOfTissues, numberOfCellTypes, 
                             assayID, tissueID, cellTypeID, idToName) {
  
  datasetBodySpecific <- paste(cellCount, numberOfAssays, numberOfTissues, numberOfCellTypes, sep = "_")
  resultTableSpecific <- paste(assayID, tissueID, cellTypeID, sep = "_")

  return(list(
    datasetBodySpecific = datasetBodySpecific, 
    resultTableSpecific = resultTableSpecific,
    idToName = idToName
    ))
}

# Power calculation: simplified gamma model without optimizing the read depth
powerSRDRD <- function(nSamples, nCells, gamma.fits, disp.fun.param) {
    
    # Setting up the cell type specification
    gamma.fits$ct <- "New_ct"
    disp.fun.param$ct <- "New_ct"
    
    return(power.sameReadDepth.restrictedDoublets(nSamples = nSamples, 
                                                  nCells = nCells,
                                                  ct.freq = 1, 
                                                  type = "eqtl",
                                                  ref.study = scPower::eqtl.ref.study,
                                                  ref.study.name = "Blueprint (Monocytes)",
                                                  cellsPerLane = nCells,
                                                  gamma.parameters = gamma.fits[gamma.fits$matrix == "complete",],
                                                  ct = "New_ct", 
                                                  disp.fun.param = disp.fun.param,
                                                  mappingEfficiency = 0.8,
                                                  min.UMI.counts = 3,
                                                  perc.indiv.expr = 0.5,
                                                  sign.threshold = 0.05,
                                                  MTmethod = "Bonferroni",
                                                  multipletRate = 0))
}

# Writing a data frame into a data table inside PostgreSQL database
# Final design of the data tables:
#     datasetBody table (descriptive parameters):  id, datasetBodySpecific, resultTableSpecific, idToName,
#                                                  gammaLinearFits, dispFunEstimation, geneRanks, powerResults
#     downloadBody table
#     result tables: gammaLinearFits, dispFunEstimation, geneRanks, powerResults
#                    estimates (estimating gene counts) & rsq (R squared error rate of the estimate)
# Data table names: datasetBody       (8 fields)
#                   downloadBody      (16     ")
#                   gammaLinearFits   (4      ")
#                   dispFunEstimation (3      ")
#                   geneRanks         (4      ")
#                   powerResults      (11     ")
#                   estimates         (12 + 1 ")
writeToDatabase <- function(data.frame, table.name, append = TRUE) {
  dbWriteTable(connectionInstance, table.name, data.frame, append = append)
}

mainProcessing <- function(dataset) {
  numberOfAssays <- length(levels(dataset$assay_ontology_term_id))
  numberOfTissues <- length(levels(dataset$tissue_ontology_term_id))
  numberOfCellTypes <- length(levels(dataset$cell_type_ontology_term_id))

  counts <- dataset@assays$RNA@counts
  countsSubsampled <- subsampleIntoList(counts)
  print(calculateZeroPerc(countsSubsampled$complete))
  
  # Calculating gene ranks
  geneRanks <- calculateGeneRanks(countsSubsampled$complete, idToName) 

  censorPoints <- rep(NA, length(countsSubsampled))
  names(censorPoints) <- names(countsSubsampled)
  
  meanUmi <- rep(NA, length(countsSubsampled))
  names(meanUmi) <- names(countsSubsampled)

  for(matrixName in names(countsSubsampled)) {
    # Number of cells per cell type as censoring point
    censorPoints[matrixName] <- 1 / ncol(countsSubsampled[[matrixName]])

    # Estimate the mean umi values per cell for each matrix
    meanUmi[matrixName] <- meanUMI.calculation(countsSubsampled[[matrixName]])
  }

  # Counting observed expressed genes
  nSamples <- tryCatch({
    if(!is.null(dataset@meta.data$Donor)) {
      length(levels(dataset@meta.data$Donor))
    } else if (!is.null(dataset@meta.data$Sample)) {
      length(levels(dataset@meta.data$Sample))
    } else if (!is.null(dataset@meta.data$sample)) {
      length(levels(dataset@meta.data$sample))
    } else {
      stop("Neither Donor nor Sample nor sample found in the meta data.")
    }
  }, warning = function(w) {
    warning(w)
  }, error = function(e) {
    stop(e)
  })
  expressedGenesDF <- countObservedGenes(countsSubsampled, nSamples)

  # Estimation of negative binomial paramters for each gene
  c(normMeanValues, dispParam) %<-% negBinomParamEstimation(countsSubsampled)

  # Estimation of a gamma mixed distribution over all means
  gammaFits <- gammaMixedDistEstimation(normMeanValues, censorPoints)

  # Parameterization of the parameters of the gamma fits by the mean UMI counts per cell
  # gammaLinearFits: parameter, intercept, meanUMI
  c(umiValues, gammaLinearFits, gammaFits) %<-% parameterizationOfGammaFits(gammaFits, meanUmi)
  
  # Firstly arranging gamma linear fit values for each cell type
  tmp <- gammaLinearFits
  tmp$ct <- completeDatasetID
  gammaLinearFitsDF <- rbind(gammaLinearFitsDF, tmp)
  
  # Then also arranging disp fun parameter values for each cell type
  tmp <- dispersion.function.estimation(dispParam)
  tmp$ct <- completeDatasetID
  tmp <- tmp[, c("ct", names(tmp)[-ncol(tmp)])]
  dispFunParamDF <- rbind(dispFunParamDF, tmp)
  
  # Collecting data for validation of the model
  observedGeneCounts <- mergeGeneCounts("Run 5", completeDatasetID, cellCount, "own_count10",
                                        meanUmi, expressedGenesDF$expressed.genes)
  observedGeneCountsDF <- rbind(observedGeneCountsDF, observedGeneCounts)
  
  # dispFunEstimation: asymptDisp, extraPois
  dispFunEstimation <- dispersion.function.estimation(dispParam)
  
  # Power calculation: simplified gamma model without optimizing the read depth 
  #       name, powerDetect, exp.probs. power, sampleSize, totalCells, usableCells
  #       multipletFraction, ctCells, expressedGenes
  power <- powerSRDRD(nSamples, cellCount, gammaFits, dispFunEstimation)
  power[["idToName"]] <- idToName
  
  # Descriptive parameters passed:
  #       datasetBodySpecific: cellCount, #assays, #tissues, #cellTypes,
  #       resultTableSpecific: assayID, tissueID, cellTypeID
  #       idToName: assayName, tissueName, cellTypeName (converted from ontology ids)
  descriptiveParams <- mergeDescription(cellCount,
                                        length(levels(dataset$assay_ontology_term_id)),
                                        length(levels(dataset$tissue_ontology_term_id)),
                                        length(levels(dataset$cell_type_ontology_term_id)),
                                        datasetID[[1]], datasetID[[2]], datasetID[[3]],
                                        idToName)
  # Write into files as an output
  outputResults(descriptiveParams, "descriptiveParams")
  outputResults(geneRanks, "geneRanks")
  outputResults(data.frame(idToName, gammaLinearFits), "gammaLinearFits")
  outputResults(data.frame(idToName, dispFunEstimation), "dispFunEstimation")
  outputResults(power, "powerResults")
  
  # Write into database
  #writeToDatabase(descriptiveParams, "descriptiveParams")
  #writeToDatabase(geneRanks, "geneRanks")
  #writeToDatabase(gammaLinearFits, "gammaLinearFits")
  #writeToDatabase(dispFunEstimation, "dispFunEstimation")
  #writeToDatabase(power, "powerResults")
}
```


Preparation beforehand:
```{r}
  loadPackages()
  handleFlagsTags(list("hostIP=127.0.0.1"))
  connectionInstance <<- establishDBConnection(HOSTIP)
  
  # path of dataset location
  setwd("C:/Users/Cem/Documents/Github/dataset")
  datasetFilePath <- params$dataset_path

  # Reading the data in seurat format
  # For reading .h5seurat file: LoadH5Seurat(datasetFilePath, assays = "RNA")
  # For reading .rds      file: readRDS(datasetFilePath)
  memory.limit(999999)
  wholeDataset <- readRDS(datasetFilePath)
  print("Dataset loaded successfully.")

  # Split for each unique singular assay, tissue, cell type combination
  datasetCollectionCombinedID <- unique(paste(wholeDataset@meta.data[[ASSAYNAME]],
                                              wholeDataset@meta.data[[TISSUENAME]],
                                              wholeDataset@meta.data[[CELLTYPENAME]],
                                              sep = "_"))
  
  # Gamma linear fit and dispersion values needed later for binding with scPower
  # They are also used to estimate gene counts
  observedGeneCountsDF <- data.frame()
  gammaLinearFitsDF <- data.frame()
  dispFunParamDF <- data.frame()
  
  expressedGenesDF <- data.frame()
  gammaFits <- data.frame()
  gammaLinearFits <- data.frame()
  dispFunEstimation <- data.frame()
  power <- data.frame()
  
  numberOfAssays <- 0
  numberOfTissues <- 0
  numberOfCellTypes <- 0
  idToName <- ""
  cellCount <- 0
  chunk_size <- 1000 # Max number of cells to keep in each chunk
  chunk_index <- 0
```


Main
Loop through cell types:
```{r}
  for(datasetID in datasetCollectionCombinedID){
      # datasetID: {[assayID], [tissueID], [cellTypeID]}
      completeDatasetID <- datasetID
      datasetID <- strsplit(datasetID, split = "_")[[1]]
      
      indexOnCollection <- which(sapply(datasetCollectionCombinedID, function(x) x == completeDatasetID))
      print(paste0("index of dataset: ", indexOnCollection, "/", length(datasetCollectionCombinedID)))
      
      # ontology ids converted to their ontology names and concatenated
      idToName <- paste(convertIDtoName(datasetID), collapse="_")
    
  
      # covering the code block with try catch in the purpose of
      # catching error for a particular cell type combination inside any dataset
      result <- tryCatch({
        
        dataset <- subset(wholeDataset, assay_ontology_term_id == datasetID[[1]] &
                                        tissue_ontology_term_id == datasetID[[2]] &
                                        cell_type_ontology_term_id == datasetID[[3]])
        
        # cell count threshold
        # if under 50, skip to the next sample
        cellCount <- dataset@assays$RNA@counts@Dim[[2]]
        if(cellCount < 50) {
          next
        }
        
        # After subsetting, split the data into chunks
        cell.ids <- Cells(dataset)
        # split these cell IDs into chunks
        chunks <- split(cell.ids, ceiling(seq_along(cell.ids)/chunk_size))
        
        for(i in seq_along(chunks)) {
            print(paste0("index of chunk: ", i, "/", length(chunks)))
            chunk_index <- i
      
            chunk <- chunks[[i]]
            
            # subset Seurat object based on the cells in the chunk
            dataset_chunk <- subset(dataset, cells = chunk)
            
            # process it
            mainProcessing(dataset_chunk)
        }
      }, 
      
      # error handling part (currently only used for outputting related informations)
      error = function(e) {
        datasetBodySpecific <- paste(numberOfAssays, numberOfTissues, numberOfCellTypes, sep = "_")
        
        errorDF <- data.frame(completeDatasetID,
                              idToName,
                              chunk_index,
                              paste(e),
                              datasetBodySpecific,
                              cellCount)
        # errorDF <- merge(errorDF, expressedGenesDF, by = "cellCount")
        # gammaFits, gammaLinearFits, dispFunEstimation, power
                              
        colnames(errorDF)[3] <- "errorMessage"
        outputResults(errorDF, "error")
      })
      
       # skip current iteration of the loop if an error occurs
      if (inherits(result, "try-error")) {
        next
      }
  }
```


Validation by UMI counts per cell:
```{r}
  # Firstly appending data created to the ones already existing in the scPower library 
  gammaLinearFitsDF <- rbind(scPower::gamma.mixed.fits, gammaLinearFitsDF)
  dispFunParamDF <- rbind(scPower::disp.fun.param, dispFunParamDF)

  estimates.allSamples <- NULL
  # our own data generated from the dataset
  # run: 5 and count > 10
  estimates <- observedGeneCountsDF
  estimates$estimated.counts <- NA
  
  for(i in 1:nrow(estimates)){
    exp.probs <- scPower::estimate.exp.prob.count.param(
      nSamples = nSamples,
      nCellsCt = estimates$num.cells[i] / nSamples,
      meanCellCounts = estimates$meanUMI[i],
      gamma.mixed.fits = gammaLinearFitsDF,
      ct = estimates$cell.type[i],
      disp.fun.param = dispFunParamDF,
      min.counts = 10,
      perc.indiv = 0.5
    )
    estimates$estimated.counts[i] <- round(sum(exp.probs))
  }
  
  estimates$dataset <- "Training data set"
  estimates$threshold <- "Training data set - Count > 10"
  estimates.allSamples <- rbind(estimates.allSamples, estimates)

  # Calculating R squared error
  
  # Fitting a linear regression model between estimated and expressed gene counts
  model <- lm(estimates$estimated.counts ~ estimates$expressed.genes)

  # Calculate the R-squared value
  estimates$rsq <- summary(model)$r.squared
  
  # Firstly writing results into a file, then into the database
  outputResults(estimates, "estimates")
  #writeToDatabase(estimates, "estimates")
  
  # Close the connection to the database
  dbDisconnect(connectionInstance)
  # Clear memory at validation
  gc()
```


Visualizing estimate results (Not yet completed):
```{r}
  # Create a scatterplot of estimated.counts vs. expressed.genes, with meanUMI on the x-axis
  ggplot(estimates, aes(x = meanUMI, y = estimated.counts)) +
    geom_point(aes(color = cell.type)) +
    geom_line(aes(y = expressed.genes, color = cell.type), size = 1) +
    labs(x = "meanUMI", y = "estimated/expressed counts", color = "cell type") +
    theme_classic()
```


(Temporary script) 
for converting identification informations of each dataset into hash codes:
```{r}
  # set the path where the files are located
  rootPath <- "C:/Users/Cem/Documents/GitHub/Helmholtz-Workspace/Data-Descriptor/Cell-Level/scPower-wrapper/results"
  
  # get a list of all .txt files in the directory and subdirectories
  descriptiveFiles <- list.files(rootPath, recursive = TRUE, pattern = "^descriptiveParams\\.txt$", full.names = TRUE)
  
  hashResultsList <- list()
  for (file in descriptiveFiles){
    # Read the file as a data frame
    df <- read.table(file, sep = " ", header = TRUE, stringsAsFactors = FALSE)
  
    # Subset the data frame to select only the columns wanted
    result_table <- df[, c("resultTableSpecific", "idToName")]
    result_table <- result_table[seq(1, nrow(result_table), by = 2), ]
    
    hashResults <- list()
    resultTableSpecific <- result_table[[1]]
    idToName <- result_table[[2]]
    
    for (i in seq_along(idToName)){
      hash <- generateID(resultTableSpecific[[i]], idToName[[i]])
      hashResults <- append(hashResults, hash)
    }
    
    hashResultsList[[length(hashResultsList) + 1]] <- hashResults
  }
```


for each of the result tables pushing data into the database:
```{r}
  # set the path where the files are located
  rootPath <- "C:/Users/Cem/Documents/GitHub/Helmholtz-Workspace/Data-Descriptor/Cell-Level/scPower-wrapper/results"
  
  # get a list of all .txt files in the directory and subdirectories
  dispFunEstimationFiles <- list.files(rootPath, recursive = TRUE, pattern = "^dispFunEstimation\\.txt$", full.names = TRUE)
  gammaLinearFitsFiles <- list.files(rootPath, recursive = TRUE, pattern = "^gammaLinearFits\\.txt$", full.names = TRUE)
  geneRanksFiles <- list.files(rootPath, recursive = TRUE, pattern = "^geneRanks\\.txt$", full.names = TRUE)
  powerResultsFiles <- list.files(rootPath, recursive = TRUE, pattern = "^powerResults\\.txt$", full.names = TRUE)
  
  dispFunResultsDF <- data.frame()
  for (i in seq_along(dispFunEstimationFiles)){
    # Read the file as a data frame
    dispFunDF <- read.table(dispFunEstimationFiles[[i]], sep = " ", header = TRUE, stringsAsFactors = FALSE)
  
    # Subset the data frame to select only the columns wanted
    result_table <- dispFunDF[, c("asymptDisp", "extraPois")]
    result_table <- result_table[seq(1, nrow(result_table), by = 2), ]
    rownames(result_table) <- NULL
    
    # merge hash values as the primary key to the table
    result_table$primary_key <- hashResultsList[[i]]
    result_table <- result_table[, c("primary_key", names(result_table)[-ncol(result_table)])]
    
    dispFunResultsDF <- rbind(dispFunResultsDF, result_table)
  }
  
  #writeToDatabase(dispFunResultsDF, "dispFunEstimationResults")
  
  #############################################################################################
  
  gammaLinearFitResultsDF <- data.frame()
  for (i in seq_along(gammaLinearFitsFiles)){
    # Read the file as a data frame
    gammaLinearFitsDF <- read.table(gammaLinearFitsFiles[[i]], sep = " ", header = TRUE, stringsAsFactors = FALSE)
  
    # Subset the data frame to select only the columns wanted
    result_table <- gammaLinearFitsDF[, c("parameter", "intercept", "meanUMI")]
    to_delete <- seq(7, nrow(result_table), by = 7)
    result_table <- result_table[-to_delete, ]
    rownames(result_table) <- NULL
    
    # merge hash values as the primary key to the table
    primary_keys <- rep(hashResultsList[[i]], each=6, length.out=nrow(result_table))
    result_table$primary_key <- primary_keys
    result_table <- result_table[, c("primary_key", names(result_table)[-ncol(result_table)])]
    
    gammaLinearFitResultsDF <- rbind(gammaLinearFitResultsDF, result_table)
  }
  
  #writeToDatabase(gammaLinearFitResultsDF, "gammaLinearFitResults")
  
  #############################################################################################
  
  geneRankResultsDF <- data.frame()
  for (i in seq_along(geneRanksFiles)){
    # Read the file as a data frame
    geneRanksDF <- read.table(geneRanksFiles[[i]], sep = " ", header = TRUE, stringsAsFactors = FALSE)
  
    # Subset the data frame to select only the columns wanted
    result_table <- geneRanksDF[, c("gene_symbol", "cumFraction", "rank", "indicator")]
    result_table <- result_table[!(result_table$gene_symbol == "gene_symbol"), ]
    rownames(result_table) <- NULL
    
    geneRankResultsDF <- rbind(geneRankResultsDF, result_table)
  }
  
  #writeToDatabase(geneRankResultsDF, "geneRanks")
  
  #############################################################################################
  
  powerResultsDF <- data.frame()
  for (i in seq_along(powerResultsFiles)){
    # Read the file as a data frame
    powerResult <- read.table(powerResultsFiles[[i]], sep = " ", header = TRUE, stringsAsFactors = FALSE)
  
    # Subset the data frame to select only the columns wanted
    result_table <- powerResult[, c("name", "powerDetect", "exp.probs", "power", "sampleSize", "totalCells", "usableCells", "multipletFraction", "ctCells", "expressedGenes")]
    result_table <- result_table[seq(1, nrow(result_table), by = 2), ]
    rownames(result_table) <- NULL
    
    # merge hash values as the primary key to the table
    result_table$primary_key <- hashResultsList[[i]]
    result_table <- result_table[, c("primary_key", names(result_table)[-ncol(result_table)])]
    
    powerResultsDF <- rbind(powerResultsDF, result_table)
  }
  
  #writeToDatabase(powerResultsDF, "powerResults")
```


combining data for creating main table
```{r}
  # What main table parameters look like:
  # datasetBody table (descriptive parameters):  id, datasetBodySpecific, resultTableSpecific, idToName,
  #                                                 gammaLinearFits, dispFunEstimation, geneRanks, powerResults

  # scrapping descriptive parameters from the .txt files
  descriptiveParams <- data.frame()
  
  for (file in descriptiveFiles){
    # Read the file as a data frame
    result_table <- read.table(file, sep = " ", header = TRUE, stringsAsFactors = FALSE)
    result_table <- result_table[seq(1, nrow(result_table), by = 2), ]
    rownames(result_table) <- NULL
    
    descriptiveParams <- rbind(descriptiveParams, result_table)
  } 

  # converting hash results data frame into a vector of hash values
  hashAsList <- list()
  
  for (hashResults in hashResultsList){
    for(hash in hashResults){
      hashAsList <- append(hashAsList, hash)
    }
  }
  
  # adding hashes into already existing main data frame
  descriptiveParams$primary_key <- hashAsList
  
  # scrapping gammaLinearFits, dispFunEstimations and powerResults from the database
  gammaLinearList <- list()
  dispFunList <- list()
  powerResultsList <- list()
  
  for (hash in hashAsList){
    # convert binary data to a format that can be included in a SQL query
    target_value <- charToRaw(hash)
    
    # Convert the target value to PostgreSQL special escape syntax
    escaped_target_value <- paste0("E'\\\\x", paste(rawToChar(as.raw(target_value)), collapse = ""), "'")
    
    # Then include it in the query string
    query_gammaLinear <- paste0("SELECT * FROM ", "gamma_linear_fit_results", " WHERE ", "primary_key", " = ", escaped_target_value)
    query_dispFun <- paste0("SELECT * FROM ", "disp_fun_estimation_results", " WHERE ", "primary_key", " = ", escaped_target_value)
    query_powerResults <- paste0("SELECT * FROM ", "power_results", " WHERE ", "primary_key", " = ", escaped_target_value)
    
    # Finally execute the query
    result_gammaLinear <- dbGetQuery(connectionInstance, query_gammaLinear)[1:6,]
    result_dispFun <- dbGetQuery(connectionInstance, query_dispFun)[1,]
    result_powerResults <- dbGetQuery(connectionInstance, query_powerResults)[1,]
    
    # convert blob field -> text
    primary_key <- paste(result_gammaLinear$primary_key[[1]], collapse = "")
    result_gammaLinear$primary_key <- primary_key
    result_dispFun$primary_key <- primary_key
    result_powerResults$primary_key <- primary_key
    
    # convert results into json and append them
    gammaLinearList <- append(gammaLinearList, toJSON(result_gammaLinear))
    dispFunList <- append(dispFunList, toJSON(result_dispFun))
    powerResultsList <- append(powerResultsList, toJSON(result_powerResults))
  }
  
  # adding result tables into main table as json instances
  descriptiveParams$gamma_linear_fits <- gammaLinearList
  descriptiveParams$disp_fun_estimations <- dispFunList
  descriptiveParams$power_results <- powerResultsList
  
  # adding gene ranks
  geneRanksList <- list()
  
  for (idToName in descriptiveParams$idToName){
    # firstly changing idToName into an sql readable format
    idToName <- gsub("'", "''", idToName)
    idToName <- paste0("'", idToName, "'")
    
    query_geneRanks <- paste0("SELECT * FROM ", "gene_ranks", " WHERE ", "indicator", " = ", idToName)
    result_geneRanks <- dbGetQuery(connectionInstance, query_geneRanks)
    geneRanksList <- append(geneRanksList, toJSON(result_geneRanks))
  }
  
  descriptiveParams$gene_ranks <- geneRanksList
  
  # beautifying data frame a little
  descriptiveParams <- descriptiveParams %>% rename(dataset_body_specific = datasetBodySpecific)
  descriptiveParams <- descriptiveParams %>% rename(result_table_specific = resultTableSpecific)
  descriptiveParams <- descriptiveParams %>% rename(id_to_name = idToName)
  
  descriptiveParams <- select(descriptiveParams, primary_key, everything())
  
  # adding result tables to the main table
  apply(descriptiveParams, 1, function(row) {
    query <- sprintf("INSERT INTO main_table (primary_key, 
                     dataset_body_specific,
                     result_table_specific,
                     id_to_name,
                     gamma_linear_fits, 
                     disp_fun_estimations,
                     power_results,
                     gene_ranks) VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')", 
                     row["primary_key"],
                     row["dataset_body_specific"],
                     row["result_table_specific"],
                     escapeQuotes(row["id_to_name"]),
                     escapeQuotes(row["gamma_linear_fits"]),
                     escapeQuotes(row["disp_fun_estimations"]),
                     escapeQuotes(row["power_results"]),
                     escapeQuotes(row["gene_ranks"]))
    
    dbExecute(connectionInstance, query)
  })
```


(RECOMB)
Example results (number of cells) :
```{r}
  lapply(c("tidyverse", "pheatmap"), library, character.only = TRUE)

  metadata <- wholeDataset@meta.data

  cell_counts <- metadata %>%
    group_by(tissue, cell_type) %>%
    summarize(Count = n()) %>%
    spread(key = cell_type, value = Count, fill = 0)
  
  heatmap_data <- cell_counts %>%
    column_to_rownames("tissue") %>%
    as.matrix()
  
  #pheatmap(heatmap_data,
  #       scale = "none",
  #       cluster_rows = T,
  #       cluster_cols = T)
  
  # for one tissue datasets
  #pheatmap(heatmap_data, 
  #         scale = "none", 
  #         cluster_rows = FALSE, 
  #         cluster_cols = TRUE)
  
  tissue_names <- row.names(heatmap_data)
  cell_types <- colnames(heatmap_data)
  
  # Create a data frame from the matrix, and add tissue names as a column
  data_frame <- as.data.frame(heatmap_data)
  data_frame$Tissue <- tissue_names
  
  # Melt the data frame to get it in long format
  library(reshape2)
  long_data <- melt(data_frame, id.vars = "Tissue", variable.name = "CellType", value.name = "Count")
  
  # Save the long data as a CSV string
  csv_string <- paste(capture.output(write.csv(long_data, row.names = FALSE)), collapse = "\n")
  print(csv_string)
```


(RECOMB)
Results for #genes
```{r}
  # Load libraries
  lapply(c("tidyverse"), library, character.only = TRUE)
      
  # Function to calculate the number of expressed genes for a given tissue and cell type
  num_expressed_genes <- function(cells, seurat_obj) {
    if (length(cells) == 0) {
      return(0)
    }
    
    counts_sub <- seurat_obj@assays$RNA@counts[, cells, drop = FALSE]
    num_genes <- sum(apply(counts_sub, 1, function(x) any(x > 0)))
    return(num_genes)
  }

  # Create a data frame with unique tissue and cell type combinations
  tissue_cell_type_combinations <- unique(wholeDataset@meta.data %>% select(tissue, cell_type))

  # Calculate the number of expressed genes for each unique combination of tissue and cell type
  tissue_cell_type_combinations$num_genes <- mapply(function(tissue, cell_type) {
    cells <- rownames(wholeDataset@meta.data[wholeDataset@meta.data$tissue == tissue & wholeDataset@meta.data$cell_type == cell_type,])
    num_expressed_genes(cells, wholeDataset)
  }, tissue_cell_type_combinations$tissue, tissue_cell_type_combinations$cell_type)
```


```{r}
  tissue_names <- unique(tissue_cell_type_combinations$tissue)
  cell_types <- unique(tissue_cell_type_combinations$cell_type)
  
  # Create a data frame from the matrix, and add tissue names as a column
  data_frame <- tissue_cell_type_combinations
  data_frame$Tissue <- tissue_names
  
  # Melt the data frame to get it in long format
  library(reshape2)
  long_data <- melt(data_frame, id.vars = "tissue", variable.name = "cell_type", value.name = "num_genes")
  
  # Save the long data as a CSV string
  csv_string <- paste(capture.output(write.csv(long_data, row.names = FALSE)), collapse = "\n")
  print(csv_string)
```
